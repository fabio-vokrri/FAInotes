\section{Constraint Satisfaction Problems}
In standard search, the basic idea is that problems can be solved by searching the state space, that is a graph in which nodes represent states and edges between them represent actions. In this type of search algorithms, the states are atomic, indivisible, like a \textit{black box}: for each problem, we need domain-specific heuristic function to describe the transition between states.

In \textbf{constraint satisfaction problems}, \textbf{CSP} for short, we break open this black box by using a factored representation for each state, that consists of a set of variables, each of which have a value. A CSP is solved if each variable has a value that satisfies all the constraints on that variable.

CSP search algorithms take advantage of the structure of states and use a general heuristic to enable the solution of complex problems. The main idea is that we can eliminate large portions of the search space by identifying values that violate constraints on variables. A CSP consists of three components:
\begin{itemize}
    \item $\mathcal{X} =\{X_1, ..., X_n\}$ is a set of variables;
    \item $\mathcal{D} =\{D_1, ..., D_n\}$ is a set of domains, one for each variable;
    \item $\mathcal{C}$ is a set of constraints that specify valid combinations of values.
\end{itemize}

A domain $D_i$ is a set of allowable values $\{v_1, ..., v_k\}$ for each variable $X_i$. Each constraint $\mathcal{C}_j$ consists of a pair $\langle scope,\; rel\rangle$, where $scope$ is a tuple of variables that participate in the constraint, and $rel$ is a relation that defines the valid values for those variables. A relation can be represented as an explicit set of all tuples of values that satisfy the constraint, or as a function that can compute whether or not a tuple is a member of the solution.

The goal of the CSP is to assign values to the variables, such that 
    $$\{X_i=v_i, X_j=v_j, ...\}.$$ 
An assignment is \textbf{consistent} if does not violate any constraints and is \textbf{complete} if all variables are assigned a value. A solution to a CSP is a consistent and complete assignment. If all the domains have fixed size $d$, there are $O(d^n)$ complete assignments possible.

Every CSP can be visualized as a constraint graph: the nodes of the graph correspond to variables of the problem and the edge connects any two variables that participate in a constraint. This type of representation for the problem can dramatically speed up the search problem, by showing that some variables are independent sub-problems. Additionally, we will consider only binary constraints, in which only two variables are involved, because higher order constraints can be transformed in a CSP with only binary constraints through simple transformations.

\subsection{Constraints Propagation - Arc consistency}
A variable in a CSP problem is arc-consistent if every value in its domain satisfies the variable's binary constraints. More formally, $X_i$ is arc-consistent with respect to another variable $X_j$ if there is some value in the domain $D_j$ that satisfies the binary constraint in the arch $(X_i, X_j)$. In other words, arc consistency is a property that allows to remove from the domain of a variable $X$ every value that is inconsistent with the values in the domain of another variable $Y$. 

The most popular algorithm for enforcing the arc-consistency property on a CSP problem is called \textbf{AC-3}, which maintains a queue of arcs to consider. Initially, the queue contains all the arcs in the CSP. Then, the algorithm pops off an arbitrary arc $(X_i, X_j)$ and makes $X_i$ arc-consistent with respect to $X_j$. If this leaves $D_i$ unchanged, the algorithm moves on the next arc, but if this operation revises the domain $D_i$ (making it smaller), then we add to the queue all arcs $X_k, X_i$, where $X_k$ is a neighbor of $X_i$. This is necessary because, by reducing $D_i$, we might enable further reductions in $D_k$, even if we've already applied the algorithm to that node. If $D_i$ is revised down to nothing, then we know that the whole CSP problem has no consistent solution and the algorithm can immediately return failure. Otherwise, we keep checking, trying to remove values from the domains of variables until no more arcs are in the queue. At this point we are left with a CSP equivalent to the initial one, but the arc consistent one will be faster to search because its variables have smaller domains. The complexity of AC-3 is $O(cd^3)$ in the worst case scenario.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{algorithms/AC-3.png}
    \label{fig:ac_3_algorithm}
\end{figure}


\subsection{Backtracking Search for CSP}
Sometimes we can finish the constraint propagation process and still have variables with multiple possible values. In this case we have to search a solution. For a CSP problem with $n$ variables of domain size $d$ we would end up with a search tree where all the complete assignments are leaf nodes at depth $n$. But, the branching factor at the top level would be $nd$ because any of $d$ values can be assigned to any of $n$ variables. At the next level, the branching factor is $(n-1)d$ and so on for $n$ levels. So the tree has $n!d^n$ leaves, even though there are only $d^n$ possible assignments.

We can remove the $n!$ factor by recognizing that CSP have the \textbf{commutative property}. A problem is said to be commutative if the order of any given set of actions does not matter. In CSPs it makes no difference if we first assign a value to a variable and then to another, or the other way around. Therefore, we need only to consider a single variable at each node in the search tree. At each level of the tree we must choose which variable we will deal with, but we never have to backtrack over that choice. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{algorithms/Backtracking Search for CSP.png}
    \label{fig:backtracking_search_for_CSP_algorithm}
\end{figure}

Backtracking search algorithm for CSP repeatedly chooses an unassigned variable and tries all values in the domain of that variable in turn, trying to extend each one into a solution recursively. If the call succeeds, the solution is returned, otherwise the assignment is restored to the previous state, from which we try all the remaining values. If no value works we return a failure. This algorithm can be improved by using domain-independent heuristics that take advantage of the factored representation of the CSP. The functions \code{SELECT-UNASSIGNED-VARIABLE} and \code{ORDER-DOMAIN-VALUES} are the heart of the backtracking algorithm, which implement a general purpose heuristics. Also, the \code{INFERENCE} function is really important, as it simplifies the problem by relaxing some constraints.

\subsubsection{Variable ordering}
There are various strategies we can implement in order to select an unassigned variable. The simplest one is to choose variables in order or randomly. There are better heuristics, like choosing the variable with the fewest possible values, called \textbf{minimum-remaining-values} (\textbf{MRV}). This strategy is also called "fail-first" as it picks a variable that is most likely to cause a failure soon, thereby pruning the tree.

Another strategy is the \textbf{degree heuristic}, which attempts to reduce the branching factor on future choices by selecting the variable that is involved in the largest number of constraints on other unassigned variables. The MRV heuristic is usually more powerful, but the degree heuristic can be useful as a tie-breaker, when multiple values can be chosen.

Once a variable is selected, the algorithm must decide on the order to examine its values. An efficient algorithm is the \textbf{least-constraining-value} heuristic, which prefers the value that rules out the fewest choices for the neighboring variables in the constraint graph.

Variables should be selected following the "fail-first" principle, while its values should follow the "fail-last" principle. This is because every variable has to be assigned eventually, so by choosing the ones that are likely to fail first, we will have fewer successful assignments to backtrack over. On the other hand, for value ordering we need only one solution, so it makes sense to look for the most likely values first.

\subsubsection{Forward Checking}
The AC-3 algorithm can reduce the domains of variables before we begin the search, but inference can be more powerful during the search. One simple type of inference is \textbf{forward checking}. Whenever a variable $X$ is assigned, the forward checking algorithm establishes arc consistency for it: for each unassigned variable $Y$ connected to $X$ by a constraint, it deletes from $Y$'s domain any value that is inconsistent with the value chosen for $X$. A problem with forward checking is that although it detects many inconsistencies, it does not detect them all.

Given $n$ variables, the size of the domain $d$ and the largest number of constraint that involve any given variable $s$, such that $s\le n-1$, the complexity of forward checking is $O(snd)$.

\subsection{Local Search}
We can efficiently solve CSPs using another paradigm: \textbf{local search}. It uses a complete state formulation where each state assigns a value to every variable, and the search changes the value of one variable at a time. In other words, it starts from a random solution and modifies it a little bit until we reach a feasible solution. This strategy uses the \textbf{hill-climbing} algorithm to evaluate whether or not the modified solution improves the current one. Considering the states of a problem as laid out in a state-space landscape, each point has an "elevation", defined by the value of the objective function; the problems is narrowed down to finding the global maximum value. The only problem in this kind of algorithms is that they can stop at local maxima, yielding a sub-optimal solution.